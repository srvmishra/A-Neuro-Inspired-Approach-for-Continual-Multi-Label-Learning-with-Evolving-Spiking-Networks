# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HVGGci4e-_r_uv3u67o7hIrFLTLPE8TQ
"""

import torch
from torchvision import datasets
from torchvision import transforms
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models
import torch.optim as optim
from torchsummary import summary
import numpy as np
import matplotlib.pyplot as plt

transform = transforms.ToTensor()

train_dataset = datasets.MNIST('./', train=True, download=True, transform=transform)
train_dataloader = DataLoader(train_dataset, batch_size=8)

test_dataset = datasets.MNIST('./', train=False, download=True, transform=transform)
test_dataloader = DataLoader(test_dataset, batch_size=8)

# transform = transforms.Compose([transforms.Resize(224),  transforms.ToTensor()])

# train_dataset = datasets.CIFAR10('./', train=True, download=True, transform=transform)
# train_dataloader = DataLoader(train_dataset, batch_size=8)

# test_dataset = datasets.CIFAR10('./', train=False, download=True, transform=transform)
# test_dataloader = DataLoader(test_dataset, batch_size=8)

class LeNet(nn.Module):

    # network structure
    def __init__(self):
        super(LeNet, self).__init__()
        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1   = nn.Linear(16*5*5, 120)
        self.fc2   = nn.Linear(120, 84)
        self.fc3   = nn.Linear(84, 10)

    def forward(self, x):
        '''
        One forward pass through the network.
        
        Args:
            x: input
        '''
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))
        x = x.view(-1, self.num_flat_features(x))
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

    def num_flat_features(self, x):
        '''
        Get the number of features in a batch of tensors `x`.
        '''
        size = x.size()[1:]
        return np.prod(size)

model = LeNet()

summary(model.cuda(), (1, 28, 28))

optimizer = optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()

device = torch.device("cuda:1")

def accuracy_score(model, dataloader):
  model.to(device)
  model.eval()
  n_correct = 0
  for x, y in dataloader:
    x, y = x.to(device), y.to(device)
    yhat = model(x)
    preds = torch.argmax(yhat, dim=1)
    n_correct += (preds == y).sum().detach().cpu().numpy()
  acc = n_correct/len(dataloader.dataset)
  return acc

def train(model, traindata, testdata, optimizer, criterion, epochs):
  model.to(device)
  for epoch in range(epochs):
    train_epoch_loss = 0
    model.train()
    for x, y in traindata:
      x, y = x.to(device), y.to(device)
      yhat = model(x)
      loss = criterion(yhat, y)

      loss.backward()
      optimizer.step()
      optimizer.zero_grad()

      train_epoch_loss += loss.detach().cpu().numpy()

    model.eval()
    test_epoch_loss = 0 
    for x, y in testdata:
      x, y = x.to(device), y.to(device)
      yhat = model(x)
      loss = criterion(yhat, y)

      test_epoch_loss += loss.detach().cpu().numpy()

    train_epoch_loss /= len(traindata.dataset)
    test_epoch_loss /= len(testdata.dataset)

    train_accuracy = accuracy_score(model, traindata)
    test_accuracy = accuracy_score(model, testdata)

    print("Epoch: {}, train loss: {}, train acc.: {}, test loss: {}, test acc.: {}".format(epoch, train_epoch_loss, train_accuracy, test_epoch_loss, test_accuracy))

  return


if __name__=="__main__":
    train(model, train_dataloader, test_dataloader, optimizer, criterion, 10)